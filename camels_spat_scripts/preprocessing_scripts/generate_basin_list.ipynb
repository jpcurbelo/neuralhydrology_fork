{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "from functools import partial\n",
    "import concurrent.futures\n",
    "\n",
    "sys.path.append('..')\n",
    "from utils_camels_spat import validate_basin_data, plot_missing_data_heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ('CAMELS_spat_NH', 'camels_spat')\n",
    "countries = [\"USA\"]\n",
    "# countries = [\"CAN\"]\n",
    "\n",
    "# 'countries' to string and lowercase\n",
    "countries_str = '-'.join(countries).lower()\n",
    "\n",
    "NUM_BASINS = 2000\n",
    "StartDate = \"1975-10-01\"\n",
    "EndDate = \"2019-09-30\"\n",
    "# StartDate = \"1980-10-01\"\n",
    "# EndDate = \"2008-09-30\"\n",
    "# StartDate = \"1980-10-01\"\n",
    "# EndDate = \"2010-09-30\"\n",
    "\n",
    "MULTIPROCESSING = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 531 basins as reference from 531_basin_file.txt (list of basins IDs)\n",
    "lines = []\n",
    "# Open the file in read mode\n",
    "with open(\"531_basin_file.txt\", 'r') as file:\n",
    "    # Read each line and append it to the list\n",
    "    for line in file:\n",
    "        lines.append(line.strip())  # Remove any leading/trailing whitespace\n",
    "\n",
    "# Print the lines to verify\n",
    "basin531_ref = set(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USA 662 -> 463 125 not in 531\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store basin information\n",
    "selected_basins = []\n",
    "df_basins_missing = pd.DataFrame()\n",
    "counter = 0\n",
    "counter_not_in_ref = 0\n",
    "not_to_stop = True\n",
    "for country in countries:\n",
    "    data_dir = f\"../../../../../gladwell/hydrology/SUMMA/summa-ml-models/{dataset[0]}/CAMELS_spat_{country}\"\n",
    "    basins = sorted(os.listdir(data_dir))\n",
    "    \n",
    "    if MULTIPROCESSING:\n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            # Define a partial function to pass the data_dir\n",
    "            process_basin_partial = partial(validate_basin_data, data_dir=data_dir, start_date=StartDate, end_date=EndDate)\n",
    "            \n",
    "            # Process each basin concurrently\n",
    "            results = [executor.submit(process_basin_partial, basin) for basin in basins]\n",
    "            \n",
    "            # Wait for all results to be available\n",
    "            for result in concurrent.futures.as_completed(results):\n",
    "                \n",
    "                basin, basin_ok, date_presence = result.result()\n",
    "                \n",
    "                # Append date_presence to the dataframe\n",
    "                if date_presence is not None:\n",
    "                    # df_basins_missing[basin] = date_presence\n",
    "                    # Create a DataFrame from the basin and date_presence\n",
    "                    df_to_concat = pd.DataFrame({basin: date_presence})\n",
    "                    # Concatenate the new DataFrame with df_basins_missing\n",
    "                    df_basins_missing = pd.concat([df_basins_missing, df_to_concat], axis=1)\n",
    "                    \n",
    "                    # Check if the basin is in the reference list\n",
    "                    basin_id = basin.split('_')[-1]\n",
    "                    basin_id = basin_id.split('.')[0]\n",
    "                    if basin_id not in basin531_ref:\n",
    "                        # print(f\"Basin {country}_{basin_id} not in the reference list (531)\")\n",
    "                        counter_not_in_ref  += 1\n",
    "                \n",
    "                if basin_ok:\n",
    "                    # print(counter, basin_ok)\n",
    "                    selected_basins.append(basin)\n",
    "                    \n",
    "                    counter += 1\n",
    "                    if counter == NUM_BASINS:\n",
    "                        break\n",
    "                    \n",
    "        print(country, len([res for res in results if res.result() is not None]), '->', len(selected_basins), \\\n",
    "            f'{counter_not_in_ref} not in 531')\n",
    "        \n",
    "    else:\n",
    "        # Initialize lists to store basin information\n",
    "        for basin in basins[:100]:\n",
    "            # print(counter, basin)\n",
    "            _, basin_ok, date_presence = validate_basin_data(basin, data_dir, StartDate, EndDate)\n",
    "            # print(basin_ok, date_presence)\n",
    "            \n",
    "            # Append date_presence to the dataframe\n",
    "            if date_presence is not None:\n",
    "                df_basins_missing[basin] = date_presence\n",
    "            \n",
    "            if basin_ok:\n",
    "                print(counter, basin)\n",
    "                selected_basins.append(basin)\n",
    "                \n",
    "                counter += 1\n",
    "                if counter == NUM_BASINS:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract start and end years\n",
    "start_year = pd.to_datetime(StartDate).year\n",
    "end_year = pd.to_datetime(EndDate).year\n",
    "\n",
    "# Write all selected basin names to a file named after the counter\n",
    "with open(f\"{len(selected_basins)}_basin_{dataset[1]}_{start_year}-{end_year}_{countries_str}.txt\", \"w\") as f:\n",
    "    for basin_name in sorted(selected_basins):\n",
    "        f.write(basin_name.split('.')[0] + \"\\n\")\n",
    "    \n",
    "    # Remove last newline character\n",
    "    f.seek(f.tell() - 1)\n",
    "    f.truncate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to remove file extension\n",
    "df_basins_missing.columns = [col.split('.')[0] for col in df_basins_missing.columns]\n",
    "\n",
    "# Date column to string format and YYYY-MM-DD if needed\n",
    "if df_basins_missing.index.dtype == 'datetime64[ns]':\n",
    "    df_basins_missing.index = df_basins_missing.index.strftime('%Y-%m-%d')\n",
    "\n",
    "plot_missing_data_heatmap(df_basins_missing, dataset, start_year=start_year, end_year=end_year, countries_str=countries_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-nh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
